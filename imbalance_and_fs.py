# -*- coding: utf-8 -*-
"""Imbalance and FS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14d1B3Jfq67xQOSwGG8si_LnkfTlK-9Yn
"""

# Run only if using Google Colab
!pip install imbalanced-learn shap lightgbm

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import (
    f1_score, confusion_matrix, classification_report,
    matthews_corrcoef, roc_auc_score
)
from sklearn.feature_selection import mutual_info_classif, RFE

from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import TomekLinks

import shap
import warnings
warnings.filterwarnings('ignore')

from google.colab import files
uploaded = files.upload()

def load_and_prepare_dataset(file_path, label_column):
    df = pd.read_csv(file_path)

    # Binary label unification
    if label_column.lower() in ['bug', 'bugs', 'defect', 'defects', 'class', 'label']:
        if df[label_column].dtype == object:
            df['defect'] = df[label_column].astype(str).str.lower().map({
                'yes': 1, 'true': 1, '1': 1, 'y': 1, "b'y'": 1,
                'no': 0, 'false': 0, '0': 0, 'n': 0, "b'n'": 0
            })
        else:
            df['defect'] = df[label_column].apply(lambda x: 1 if x > 0 else 0)

        df.drop(columns=[label_column], inplace=True)

    # Drop non-numeric columns and fill missing values
    df = df.select_dtypes(include=[np.number]).fillna(df.median(numeric_only=True))

    # Normalize features
    X = df.drop(columns='defect')
    y = df['defect']
    X_scaled = MinMaxScaler().fit_transform(X)

    return X_scaled, y, X.columns.tolist()

# You can change label_column based on your dataset
file_label_map = {
    'ant-1.7.csv': 'bug',
    'camel-1.6.csv': 'bug',
    'ivy-1.2.csv': 'bug',
    'jedit-4.3.csv': 'bug',
    'log4j-1.2.csv': 'bug',
    'lucene-2.4.csv': 'bug',
    'poi-3.0.csv': 'bug',
    'synapse-1.2.csv': 'bug',
    'velocity-1.6.csv': 'bug',
    'xalan-2.7.csv': 'bug',
    'xerces-1.4.4.csv': 'bug',
    'CM1 (1) (1).csv': 'defective',
    'JM1 (3).csv': 'defective',
    'KC1 (4).csv': 'defective',
    'KC3.csv': 'defective',
    'KC4 (1).csv': 'defective',
    'MC1.csv': 'defective',
    'MC2.csv': 'defective',
    'MW1.csv': 'defective',
    'PC1 (2).csv': 'defective',
    'PC2.csv': 'defective',
    'PC3 (1).csv': 'defective',
    'PC4.csv': 'defective',
    'PC5 (1).csv': 'defective',
    'equinox.csv': 'bugs',
    'jdt.csv': 'bugs',
    'lucene.csv': 'bugs',
    'mylyn.csv': 'bugs',
    'pde.csv': 'bugs'
}

dataset_store = {}

for filename, label in file_label_map.items():
    try:
        X_scaled, y, feature_names = load_and_prepare_dataset(filename, label)
        dataset_store[filename] = {
            'X': X_scaled,
            'y': y,
            'features': feature_names
        }
        print(f"âœ… Loaded and processed: {filename}")
    except Exception as e:
        print(f"âŒ Error with {filename}: {e}")

def smart_load_dataset(file_path):
    df = pd.read_csv(file_path)
    original_cols = df.columns.str.lower()

    # Common label columns used in PROMISE/NASA/AEEEM
    possible_labels = ['bug', 'bugs', 'defect', 'defective', 'label', 'class']

    # Try to find a valid label column
    label_column = None
    for col in possible_labels:
        if col in original_cols.tolist():
            label_column = df.columns[original_cols.tolist().index(col)]
            break

    if label_column is None:
        raise ValueError(f"No label column found in {file_path}. Tried: {possible_labels}")

    # Convert to binary 'defect' column
    if df[label_column].dtype == object:
        df['defect'] = df[label_column].astype(str).str.lower().map({
            'yes': 1, 'true': 1, '1': 1, 'y': 1, "b'y'": 1,
            'no': 0, 'false': 0, '0': 0, 'n': 0, "b'n'": 0
        }).fillna(0)
    else:
        df['defect'] = df[label_column].apply(lambda x: 1 if x > 0 else 0)

    df.drop(columns=[label_column], inplace=True)

    # Keep only numeric columns and handle missing values
    df = df.select_dtypes(include=[np.number]).fillna(df.median(numeric_only=True))

    # Normalize features
    X = df.drop(columns='defect')
    y = df['defect']
    X_scaled = MinMaxScaler().fit_transform(X)

    return X_scaled, y, X.columns.tolist()

from google.colab import files
uploaded = files.upload()  # Upload all your CSVs again

dataset_store = {}

for filename in uploaded:
    try:
        X_scaled, y, feature_names = smart_load_dataset(filename)
        dataset_store[filename] = {
            'X': X_scaled,
            'y': y,
            'features': feature_names
        }
        print(f"âœ… Loaded and processed: {filename}")
    except Exception as e:
        print(f"âŒ Error with {filename}: {e}")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Preprocessed data store
preprocessed_data = {}

for name, data in dataset_store.items():
    X = data['X']
    y = data['y']

    # Normalize features
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    # Train/Test split (80/20 stratified)
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, stratify=y, random_state=42
    )

    preprocessed_data[name] = {
        'X_train': X_train, 'X_test': X_test,
        'y_train': y_train, 'y_test': y_test,
        'features': data['features']
    }

    print(f"âœ… Preprocessed {name}: Train={X_train.shape}, Test={X_test.shape}")

from sklearn.feature_selection import mutual_info_classif, RFE
from sklearn.linear_model import LogisticRegression
import numpy as np

# Store feature-selected datasets
feature_selected_data = {}

for name, data in preprocessed_data.items():
    X_train = data['X_train']
    X_test = data['X_test']
    y_train = data['y_train']
    feature_names = data['features']

    # Step 1: Mutual Information
    mi_scores = mutual_info_classif(X_train, y_train)
    top_k = int(0.7 * len(mi_scores))  # select top 70% features
    top_indices = np.argsort(mi_scores)[-top_k:]
    X_train_mi = X_train[:, top_indices]
    X_test_mi = X_test[:, top_indices]
    selected_features_mi = [feature_names[i] for i in top_indices]

    # Step 2: Recursive Feature Elimination (RFE)
    rfe_estimator = LogisticRegression(solver='liblinear')
    rfe = RFE(estimator=rfe_estimator, n_features_to_select=min(10, len(top_indices)))
    rfe.fit(X_train_mi, y_train)

    final_indices = [i for i, x in enumerate(rfe.support_) if x]
    X_train_final = X_train_mi[:, final_indices]
    X_test_final = X_test_mi[:, final_indices]
    final_features = [selected_features_mi[i] for i in final_indices]

    feature_selected_data[name] = {
        'X_train': X_train_final, 'X_test': X_test_final,
        'y_train': y_train, 'y_test': data['y_test'],
        'features': final_features
    }

    print(f"ðŸ” {name}: {len(final_features)} features selected â†’ {final_features}")

import pandas as pd

# Prepare data for the table
feature_table = [(name, ', '.join(info['features'])) for name, info in feature_selected_data.items()]
df_features = pd.DataFrame(feature_table, columns=['Dataset', 'Selected Features'])

# Save to CSV
df_features.to_csv('outputs/feature_selection_table.csv', index=False)

!pip install imbalanced-learn

from imblearn.over_sampling import SMOTE
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os

# Create output directory
os.makedirs("outputs", exist_ok=True)

# Store balanced datasets
balanced_data = []
comparison_table = []

for name, data in feature_selected_data.items():
    X_train = data['X_train']
    y_train = data['y_train']

    # Class distribution before SMOTE
    before = Counter(y_train)

    # Apply SMOTE
    smote = SMOTE(random_state=42)
    X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

    # Class distribution after SMOTE
    after = Counter(y_train_bal)

    # Store the balanced dataset
    balanced_data.append({
        'name': name,
        'X_train': X_train_bal,
        'y_train': y_train_bal,
        'X_test': data['X_test'],
        'y_test': data['y_test'],
        'features': data['features']
    })

    # Record for table
    comparison_table.append({
        'Dataset': name,
        'Before (0)': before[0], 'Before (1)': before[1],
        'After (0)': after[0], 'After (1)': after[1]
    })

# Convert to DataFrame
comp_df = pd.DataFrame(comparison_table)

# Save the comparison table
table_path = "outputs/class_distribution_comparison.csv"
comp_df.to_csv(table_path, index=False)
print(f"âœ… Comparison table saved to: {table_path}")

# ðŸ“Š Barplot of class distribution before and after
fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)
melted = pd.melt(comp_df, id_vars='Dataset', value_vars=['Before (0)', 'Before (1)', 'After (0)', 'After (1)'],
                 var_name='Class_Label', value_name='Count')

# Separate for before/after
before_df = melted[melted['Class_Label'].str.startswith('Before')]
after_df = melted[melted['Class_Label'].str.startswith('After')]

sns.barplot(data=before_df, x='Dataset', y='Count', hue='Class_Label', ax=axes[0])
axes[0].set_title("Before SMOTE")
axes[0].tick_params(axis='x', rotation=90)

sns.barplot(data=after_df, x='Dataset', y='Count', hue='Class_Label', ax=axes[1])
axes[1].set_title("After SMOTE")
axes[1].tick_params(axis='x', rotation=90)

plt.tight_layout()
plot_path = "outputs/class_distribution_plot.png"
plt.savefig(plot_path, dpi=300)
plt.show()
print(f"âœ… Plot saved to: {plot_path}")

from imblearn.under_sampling import TomekLinks
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os

# Create output directory if not exists
os.makedirs("outputs", exist_ok=True)

tomek_balanced_data = []
tomek_comparison_table = []

for name, data in feature_selected_data.items():
    X_train = data['X_train']
    y_train = data['y_train']

    before = Counter(y_train)
    tl = TomekLinks()
    X_resampled, y_resampled = tl.fit_resample(X_train, y_train)
    after = Counter(y_resampled)

    tomek_balanced_data.append({
        'name': name,
        'X_train': X_resampled,
        'y_train': y_resampled,
        'X_test': data['X_test'],
        'y_test': data['y_test'],
        'features': data['features']
    })

    tomek_comparison_table.append({
        'Dataset': name,
        'Before (0)': before[0], 'Before (1)': before[1],
        'After (0)': after[0], 'After (1)': after[1]
    })

tomek_df = pd.DataFrame(tomek_comparison_table)
tomek_df.to_csv("outputs/tomek_class_distribution_comparison.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)
melted_df = pd.melt(tomek_df, id_vars='Dataset', value_vars=['Before (0)', 'Before (1)', 'After (0)', 'After (1)'],
                    var_name='Class_Label', value_name='Count')

before_df = melted_df[melted_df['Class_Label'].str.startswith('Before')]
after_df = melted_df[melted_df['Class_Label'].str.startswith('After')]

sns.barplot(data=before_df, x='Dataset', y='Count', hue='Class_Label', ax=axes[0])
axes[0].set_title("Before Tomek Links")
axes[0].tick_params(axis='x', rotation=90)

sns.barplot(data=after_df, x='Dataset', y='Count', hue='Class_Label', ax=axes[1])
axes[1].set_title("After Tomek Links")
axes[1].tick_params(axis='x', rotation=90)

plt.tight_layout()
plt.savefig("outputs/tomek_class_distribution_plot.png", dpi=300)
plt.show()

from imblearn.combine import SMOTETomek
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os

# Ensure output folder exists
os.makedirs("outputs", exist_ok=True)

smote_tomek_balanced_data = []
smote_tomek_comparison_table = []

for name, data in feature_selected_data.items():
    X_train = data['X_train']
    y_train = data['y_train']

    before = Counter(y_train)

    smote_tomek = SMOTETomek(random_state=42)
    X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)

    after = Counter(y_resampled)

    smote_tomek_balanced_data.append({
        'name': name,
        'X_train': X_resampled,
        'y_train': y_resampled,
        'X_test': data['X_test'],
        'y_test': data['y_test'],
        'features': data['features']
    })

    smote_tomek_comparison_table.append({
        'Dataset': name,
        'Before (0)': before[0], 'Before (1)': before[1],
        'After (0)': after[0], 'After (1)': after[1]
    })

smote_tomek_df = pd.DataFrame(smote_tomek_comparison_table)
smote_tomek_df.to_csv("outputs/smote_tomek_class_distribution_comparison.csv", index=False)

fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)
melted_df = pd.melt(smote_tomek_df, id_vars='Dataset',
                    value_vars=['Before (0)', 'Before (1)', 'After (0)', 'After (1)'],
                    var_name='Class_Label', value_name='Count')

before_df = melted_df[melted_df['Class_Label'].str.startswith('Before')]
after_df = melted_df[melted_df['Class_Label'].str.startswith('After')]

sns.barplot(data=before_df, x='Dataset', y='Count', hue='Class_Label', ax=axes[0])
axes[0].set_title("Before SMOTE + Tomek")
axes[0].tick_params(axis='x', rotation=90)

sns.barplot(data=after_df, x='Dataset', y='Count', hue='Class_Label', ax=axes[1])
axes[1].set_title("After SMOTE + Tomek")
axes[1].tick_params(axis='x', rotation=90)

plt.tight_layout()
plt.savefig("outputs/smote_tomek_class_distribution_plot.png", dpi=300)
plt.show()

import os
import pandas as pd
from sklearn.ensemble import VotingClassifier, AdaBoostClassifier
from imblearn.ensemble import BalancedRandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import f1_score, matthews_corrcoef, make_scorer
from imblearn.metrics import geometric_mean_score

# Evaluation setup
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
results = []

# Assume this is already defined from earlier step
# smote_tomek_balanced_data = [{'name': ..., 'X_train': ..., 'y_train': ...}, ...]

for data in smote_tomek_balanced_data:
    name = data['name']
    X = data['X_train']
    y = data['y_train']

    models = {
        'Voting': VotingClassifier(
            estimators=[
                ('lr', LogisticRegression(max_iter=1000)),
                ('dt', DecisionTreeClassifier()),
                ('nb', GaussianNB())
            ],
            voting='soft',
            n_jobs=-1
        ),
        'AdaBoost': AdaBoostClassifier(
            estimator=DecisionTreeClassifier(max_depth=1),
            n_estimators=50,
            random_state=42
        ),
        'BalancedRF': BalancedRandomForestClassifier(
            n_estimators=100,
            random_state=42,
            n_jobs=-1
        )
    }

    for model_name, model in models.items():
        auc = cross_val_score(model, X, y, cv=cv, scoring='roc_auc').mean()
        f1 = cross_val_score(model, X, y, cv=cv, scoring='f1').mean()
        gm = cross_val_score(model, X, y, cv=cv, scoring=make_scorer(geometric_mean_score)).mean()
        mcc = cross_val_score(model, X, y, cv=cv, scoring=make_scorer(matthews_corrcoef)).mean()

        results.append({
            'Dataset': name,
            'Model': model_name,
            'AUC': round(auc, 4),
            'F1-Score': round(f1, 4),
            'G-Mean': round(gm, 4),
            'MCC': round(mcc, 4)
        })

# Save results
results_df = pd.DataFrame(results)
os.makedirs("outputs", exist_ok=True)
results_df.to_csv("outputs/voting_adaboost_brf_results.csv", index=False)

# Show
print(results_df)

pip install lime

import numpy as np
import lime
import lime.lime_tabular
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
import os
import pandas as pd

# Ensure output directory for LIME plots exists
os.makedirs("outputs/lime_plots", exist_ok=True)

lime_results = []

# Run LIME for each dataset
for item in smote_tomek_balanced_data:
    try:
        name = item['name']
        X_train = item['X_train']
        y_train = item['y_train']
        X_test = item['X_test']
        y_test = item['y_test']
        feature_names = item['features']

        # Train a Logistic Regression model for interpretability
        model = LogisticRegression(max_iter=1000)
        model.fit(X_train, y_train)

        # Setup LIME explainer
        explainer = lime.lime_tabular.LimeTabularExplainer(
            training_data=np.array(X_train),
            feature_names=feature_names,
            class_names=['non-defect', 'defect'],
            mode='classification'
        )

        # Choose instance to explain
        instance_idx = 3
        exp = explainer.explain_instance(X_test[instance_idx], model.predict_proba, num_features=10)

        # Save the explanation plot
        fig = exp.as_pyplot_figure()
        plot_path = f"outputs/lime_plots/lime_{name}_instance_{instance_idx}.png"
        plt.title(f"LIME Explanation: {name}")
        plt.savefig(plot_path, bbox_inches='tight')
        plt.close()

        lime_results.append({
            "Dataset": name,
            "Explained Instance": instance_idx,
            "Plot Path": plot_path
        })
    except Exception as e:
        lime_results.append({
            "Dataset": item.get('name', 'Unknown'),
            "Explained Instance": None,
            "Plot Path": f"Error: {str(e)}"
        })

# Show summary of results
pd.DataFrame(lime_results).to_csv("outputs/lime_summary.csv", index=False)

results_df = pd.DataFrame(results)
os.makedirs("outputs", exist_ok=True)
results_df.to_csv("outputs/voting_adaboost_brf_results.csv", index=False)
print(results_df)

import matplotlib.pyplot as plt
import seaborn as sns

def safe_plot_boxplot(df, metric, save_path):
    try:
        plt.clf()
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.boxplot(data=df, x='Model', y=metric, ax=ax, palette="Set2")
        ax.set_title(f"{metric} Comparison")
        ax.set_xlabel("Model")
        ax.set_ylabel(metric)
        ax.grid(True, linestyle='--', alpha=0.6)
        fig.savefig(save_path, dpi=100)  # lower DPI to prevent memory error
        plt.close(fig)
        print(f"âœ… Saved: {save_path}")
    except Exception as e:
        print(f"âŒ Failed to save {metric} plot: {e}")

# Create directory
import os
os.makedirs("outputs/plots", exist_ok=True)

# Run for each metric
safe_plot_boxplot(results_df, "F1-Score", "outputs/plots/f1_score.png")
safe_plot_boxplot(results_df, "G-Mean", "outputs/plots/gmean.png")
safe_plot_boxplot(results_df, "MCC", "outputs/plots/mcc.png")

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import (
    confusion_matrix, ConfusionMatrixDisplay,
    roc_curve, auc,
    precision_recall_curve, average_precision_score
)

# ---- Setup Output Directory ----
os.makedirs("outputs/plots", exist_ok=True)

# ---- Simulated Results (Replace this with your real model output) ----
np.random.seed(42)

datasets = ['CM1', 'JM1']
models = ['Voting', 'AdaBoost', 'BalancedRF']

results = []

for dataset in datasets:
    for model in models:
        y_test = np.random.randint(0, 2, size=100)
        y_prob = np.clip(np.random.normal(loc=0.5 + 0.2*(model == 'BalancedRF'), scale=0.2, size=100), 0, 1)
        y_pred = (y_prob >= 0.5).astype(int)

        results.append({
            'name': dataset,
            'model': model,
            'y_test': y_test.tolist(),
            'y_pred': y_pred.tolist(),
            'y_prob': y_prob.tolist()
        })

# ---- Generate Plots and Summary ----
summary_rows = []

for res in results:
    name = res['name']
    model = res['model']
    y_test = np.array(res['y_test'])
    y_pred = np.array(res['y_pred'])
    y_prob = np.array(res['y_prob'])

    safe_id = f"{name}_{model}".replace(" ", "_").replace("(", "").replace(")", "")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(cm)
    disp.plot()
    plt.title(f"{model} - {name}")
    plt.savefig(f"outputs/plots/confusion_matrix_{safe_id}.png", dpi=100)
    plt.close()

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel("FPR")
    plt.ylabel("TPR")
    plt.title(f"ROC Curve: {model} - {name}")
    plt.legend()
    plt.savefig(f"outputs/plots/roc_{safe_id}.png", dpi=100)
    plt.close()

    # PR Curve
    precision, recall, _ = precision_recall_curve(y_test, y_prob)
    pr_auc = average_precision_score(y_test, y_prob)
    plt.plot(recall, precision, label=f"AP = {pr_auc:.2f}")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title(f"PR Curve: {model} - {name}")
    plt.legend()
    plt.savefig(f"outputs/plots/pr_{safe_id}.png", dpi=100)
    plt.close()

    # Summary Row
    summary_rows.append({
        'Dataset': name,
        'Model': model,
        'AUC': roc_auc,
        'AP': pr_auc,
        'TP': cm[1, 1],
        'FP': cm[0, 1],
        'FN': cm[1, 0],
        'TN': cm[0, 0]
    })

# ---- Save Summary Table ----
summary_df = pd.DataFrame(summary_rows)
summary_df.to_csv("outputs/performance_summary_table.csv", index=False)
print("âœ… All plots and summary saved to 'outputs/plots/' and 'outputs/performance_summary_table.csv'")